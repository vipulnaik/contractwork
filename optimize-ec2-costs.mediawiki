Amazon's Elastic Cloud Computing (EC2) is the centerpiece of Amazon Web Services, the world's most widely used cloud-based infrastructure-as-a-service solution.<ref>[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html What Is Amazon EC2?]</ref><ref>[https://en.wikipedia.org/wiki/Amazon_Elastic_Compute_Cloud Amazon Elastic Compute Cloud]</ref> EC2 offers a wide array of options that, taken together, is very powerful. On the flip side, it is also extremely complicated for beginners, and not properly understanding it can mean spending significantly more on infrastructure.This page describes in considerable detail how to do a better job managing your EC2 instances to keep costs manageable. The target audience of this page is individuals or businesses whose expected annual EC2 costs are in the $10,000-$200,000 range. Given the complexity of the material here, it may not make sense to invest the time and energy in cost optimization at an annual cost of less than $10,000. If your annual costs are in excess of $200,000, it probably makes sense to hire the equivalent of a full-time dev ops engineer to manage your Amazon EC2 instances and costs.

[[Category:Amazon]]

== Steps ==
=== Understanding if EC2 is right for you ===
# Understand that EC2 is not the cheapest. In terms of price-performance ratios for the hardware alone, EC2 is far from the cheapest alternative on the market. Even accounting for reliability of service does not make it the most cost-competitive.<ref>[http://openmymind.net/Why-I-Dislike-ec2/ Why I Dislike EC2]</ref><ref>[http://deepvalue.net/ec2-is-380-more-expensive-than-internal-cluster/ EC2 is 380% more expensive than internal cluster]</ref><ref>[https://blog.serverdensity.com/saving-500k-per-month-buying-your-own-hardware-cloud-vs-colocation/ Saving $500k per month buying your own hardware – cloud vs colocation]</ref><ref>[https://moz.com/blog/mozs-2013-year-in-review Moz's 2013 Year in Review]</ref>
#* If you expect to have a lot of data transfer (outbound from your server) the Amazon Web Services can be quite expensive compared with various virtual private server (VPS) providers such as Linode and Digital Ocean. This is because AWS charges about 9 cents per GB, which translates to about $90/TB, an amount that most VPS providers offer for free with their minimalistic monthly plans (about $5 or $10 per month).<ref>[https://www.hivelocity.net/blog/AWS-bandwidth-expensive/ Why Switching to AWS May Cost You A Fortune]</ref><ref>[https://news.ycombinator.com/item?id=8704174 Comment on prohibitively expensive AWS data transfer costs (Y Combinator)]</ref><ref>[https://josephscott.org/archives/2009/01/how-much-does-one-terabyte-of-bandwidth-cost/ How Much Does One Terabyte Of Bandwidth Cost?]</ref> In other words, if you have a simple website that gets a lot of traffic, AWS is unlikely to be the right choice for you.
#* In terms of hardware performance, Amazon EC2 has historically offered worse performance than Linode and Digital Ocean for servers of the same price and similar hardware specs (in terms of vCPUs and memory). Partly, this is because of differences in the underlying architecture.<ref>[http://cosninix.com/wp/2013/06/amazon-aws-ec2-linode-digitalocean-cloudserver-showdown/ Amazon AWS EC2 vs Linode vs Digitalocean: Cloudserver showdown]</ref><ref name=reddit-comparison>[https://www.reddit.com/r/webhosting/comments/2q29dp/linode_vs_ec2_which_would_you_pick_also_anyone/ Linode vs. EC2, which would you pick? Also, anyone used 1 and 1 hosting before?]</ref>
# Understand some of the key advantages of EC2 and of Infrastructure-as-a-Service (IaaS) solutions in general.<ref>[http://blog.fugue.it/2014-08-11-minimum_viable_cloud.html Minimum Viable Cloud]</ref><ref name=reddit-comparison/><ref>[https://keithyau.wordpress.com/2014/12/17/linode-vs-aws-pricing/ Linode vs AWS pricing]</ref>
#* A flexible, scalable infrastructure that you can adapt to your changing needs.
#* Ability to deploy instances and make changes to the architecture programmatically.
#* The availability of spot instances.
#* A large number of managed services that, if used together in the same region, cost nothing (or very little) in data transfer.
# Keep in mind that you don't have to use EC2 just because you're using some other Amazon services. For instance, a number of people use Amazon S3 for cheap, flexible, and redundant bulk storage, but do not run their machines on EC2.

=== Understanding instance types ===
# Understand the different aspects of an Amazon instance type's description.<ref>[http://aws.amazon.com/ec2/pricing/ Amazon EC2 Instance Pricing]</ref><ref>[http://ec2instances.info/ Easy Amazon EC2 Instance Comparison]</ref>
#* A typical name has three parts: a letter describing the instance class (R, M, C, T, G, D, I, P, X), a number describing the generation (1, 2, 3, 4, 5), and a string describing the size within that instance class and generation (small, medium, large, xlarge, 2xlarge, 4xlarge, 8xlarge, 10xlarge, 16xlarge, 32xlarge). For instance, "r3.4xlarge" is instance type R, generation 3, and size 4xlarge.
#* A simple way of remembering what the size means is: "large" stands for 2 vCPUs, "xlarge" stands for 4 vCPUs, and ''n''xlarge means ''4n'' vCPUs. A vCPU is one "hyperthread" in the jargon of Intel, the chip manufacturer.<ref>[https://en.wikipedia.org/wiki/Hyper-threading Hyper-threading]</ref> It can naively be thought of as corresponding to one core on a consumer laptop or desktop; however, physically speaking, the Intel chips used by recent generations of EC2 instances have two vCPUs (or two threads) per core. If comparing to existing physical servers, you have to multiply the number of physical server cores by two to get the right vCPU number.<ref>[https://samrueby.com/2015/01/12/what-are-amazon-aws-vcpus/ What are Amazon AWS vCPUs?], Sam Rueby, January 12, 2016</ref><ref>[https://www.pythian.com/blog/virtual-cpus-with-amazon-web-services/ Virtual CPUs with Amazon Web Services], Marc Fielding, Pythian, June 24, 2014</ref><ref>[http://blogs.gartner.com/kyle-hilgendorf/2014/04/16/aws-moves-from-ecu-to-vcpu/ AWS moves from ECU to vCPU], Kyle Hilgendorf, Gartner, April 16, 2014</ref>
#* The instance class gives the ratio between the different parts of the instance specs. The most relevant ratio is the ratio of vCPUs to RAM. For instance, the C instance class (where C stands for compute-optimized) offers 1 vCPU for every (approximately) 2 gigabytes of RAM. The exact ratios differ slightly between different generations, since later instances do a better job squeezing out more value from the hardware.
#* Generations also differ in some of the extra features they offer. For instance, the third-generation C, M, and R classes (C3, M3 and R3) all have local SSDs, but the fourth-generation (C4, M4, and R4) do not.
#* For a given instance class and generation, size differences just mean different amounts of each resource, but in the same proportion (note that some peripheral aspects of the specs, such as SSD storage and throughput, do not scale linearly). For on-demand and reserved instances, costs scale linearly with size within a given instance type and generation. For spot instance, costs may not scale linearly since they are determined by supply and demand, but for the most common instance types, the scaling is close to linear.
#* For a given instance type and generation, it is generally possible to change a reservation type (after the reservation has already been made) to reallocate capacity between different sizes. For instance, c3.2xlarge is twice the capacity of c3.xlarge, so it is possible to change a reservation of 5 c3.2xlarge's into 10 c3.xlarge's, or into 3 c3.2xlarge's and 4 c3.xlarge's.
#* Keep in mind that the names of the instance types don't have any deeper meaning than just providing an intuitive description of the specs. Thus, for instance, C is "compute-optimized" but all this means is that the ratio of vCPUs to memory is more in favor of vCPUs than in memory. There is no specific computation-specific optimization beyond what the specs already reveal.
#* Network throughput does not quite scale linearly.
# Understand the ratios of the three main instance classes. Note that the precise ratios vary a bit across generations.
#* The R instance class is memory-optimized, and offers the most memory per vCPU (i.e., the least number of vCPUs per unit memory). The ratio is approximately 7.5 GB/vCPU.
#* The M instance class is intermediate. It offers 3.75 GB/vCPU.
#* The C instance class is compute-optimized, and offers the least memory per vCPU (i.e., the most number of vCPUs per unit memory). The ratio is approximately 1.875 GB/vCPU.
# Understand the maximum available capacities of the instances, so as to identify the limits of vertical scaling.
#* M instance class: M3 goes up to only m3.2xlarge (30 GB, 8 vCPUs). M4 goes up to m4.16xlarge (256 GB, 64 vCPUs) but lacks SSD.
#* R instance class: R3 goes up to r3.8xlarge (244 GB, 32 vCPUs). R4 goes up to r4.16xlarge (488 GB, 64 vCPUs) but lacks SSD.
#* C instance class: C3 goes up to c3.8xlarge (60 GB, 32 vCPUs). C4 goes up to c4.8xlarge (60 GB, 36 vCPUs) but lacks SSD. C5 (which is being rolled out as of December 2016) will go up to c5.18xlarge (144 GB, 72 vCPUs) and also lack SSD. 
# Understand additional constraints you may face based on the operating system and AMI you intend to use.
#* Most of the remarks in this article, as well as most online discussion of EC2, focuses on the use case of Linux/Unix instances that have no licensing costs.
#* You can also deploy EC2 instances with other operating systems such as Windows. These instances cost more (holding the instance type and purchase option constant). They also offer less flexibility with changing reservations. There are no separate licensing fees; Amazon pays for the licenses and includes them in the instance costs.<ref>[https://forums.aws.amazon.com/thread.jspa?threadID=58133 Windows Server License Cost]</ref>

=== Understanding application requirements ===
# Run your application on some instances to see how it uses various resources (computing, memory, local storage, network) and what the bottlenecks are.
#* CPU and network usage are stored in metrics in Amazon CloudWatch, Amazon's system for recording metrics. They can also be accessed in the EC2 console.
#* Memory usage is ''not'' trackable using the Amazon EC2 console. Therefore you will need to track memory usage within your application, or through another memory-logging process that you install on your instance. One such process recommended by Amazon (and that can export to CloudWatch) is collectd.<ref>[https://aws.amazon.com/about-aws/whats-new/2016/10/amazon-cloudwatch-releases-cloudwatch-collectd-plugin/ Amazon CloudWatch Releases CloudWatch collectd Plugin], October 6, 2016</ref>
#* Keep in mind that CPU and network usage data are no longer available in the EC2 console after your instances are terminated. However, they can be viewed in CloudWatch metrics (essentially the reason you can't see them in the EC2 console is that the instance isn't listed there any more).
#* CloudWatch metrics on CPU and network usage (as well as any other custom metrics that you export) are maintained for a moving window of 15 months, up from a moving window of 2 weeks earlier. Since the change was introduced recently, as of now, you can only get the metrics for the last three months.<ref>[https://aws.amazon.com/blogs/aws/amazon-cloudwatch-update-extended-metrics-retention-user-interface-update/ Amazon CloudWatch Update – Extended Metrics Retention & User Interface Update], Jeff Barr, November 1, 2016</ref>
# Identify the key variables affecting the resource usage of your applications.
#* For frontend applications, one key variable affecting resource usage is traffic levels. Identify how your resource usage (both memory and computational resources) varies with different traffic levels. Traffic levels may fluctuate daily and seasonally as well as have secular trends (i.e., long-term trends). You may wish to artificially simulate higher traffic loads using tools such as Gatling<ref>[https://en.wikipedia.org/wiki/Gatling_%28software%29 Gatling (software) (Wikipedia)]</ref> or services such as Blitz.io.
#* The size of the data that your application uses may also change, independent of traffic levels. For instance, if your application serves a website, then metrics related to the size of the website (number of pages, number of distinct user accounts) may affect resource usage. These metrics do not vary much over the short term but tend to increase over time, so you will need to extrapolate from current usage or artificially simulate larger website size or more user accounts.
# Identify interactions and trade-offs between resource usage in your code.
#* For applications that run on the Java Virtual Machine (JVM), the closer your memory is to full utilization, the more time and resources are spent in garbage collection.<ref>[http://www.dynatrace.com/en/javabook/analyzing-java-memory.html Analyzing Java Memory]</ref> This can cause CPU utilization to skyrocket and latency to increase. Similar phenomena may occur for applications that run in other environments.
#* Therefore, it's particularly important to track and understand what the original cause of bottlenecks is. Simply seeing CPU utilization skyrocket to 100% does not imply that the problem was with too little CPU. The problem could be with too little memory causing CPU resources to be forced into garbage collection.
# If you are considering running identical applications on multiple instances (typical for front-ends serving high loads), explore the trade-offs between horizontal scaling (using more instances) and vertical scaling (using larger instances). <ref>[https://en.wikipedia.org/wiki/Scalability#Horizontal_and_vertical_scaling Horizontal and vertical scaling (Wikipedia)]</ref> For instance, determine whether it's better to use a few xlarge instances, or twice as many large instances.<ref>[https://medium.com/aws-activate-startup-blog/scaling-on-aws-part-1-a-primer-dbf1276ded5a#.rtipdghpb Scaling on AWS (Part 1): A Primer], AWS Startups blog</ref>
#* '''Limits''' (in favor of horizontal scaling): Vertical scaling has fairly tight limits: there is a fairly low upper bound on the size of EC2 instances you can use (see Part 2, Step 3). With AWS's infrastructure scale, the limits on horizontal scaling are much larger (although your account might have its own limits set by AWS, you can request a limit increase). If you need 1000 vCPUs of computation, you must use at least some horizontal scaling, because even the limits of vertical scaling only get you to 64 vCPUs.
#* '''More divisibility and therefore better precision in capacity''' (in favor of horizontal scaling): Using smaller instance types allows you to more finely tune the number of instances to the traffic capacity. For instance, suppose you know your traffic requirement would need 9 c3.large instances to serve. Assuming no shared memory or other shared resource issues, If you wanted to use c3.xlarge instances, you'd need 5 of them, because you can't get 4.5 instances, therefore effectively wasting the equivalent of one c3.large in computational resources. If you used c3.2xlarge instances, you'd need 3 of them, thereby effectively wasting the equivalent of three c3.large's in computational resources. If you used c3.4xlarge's you'd need 2 of them, thereby effectively wasting the equivalent of seven c3.large's. Note that this applies both if you have very fixed traffic needs and if you have variable traffic needs but have a good system for autoscaling.
#* '''Improved availability''' (mixed, but generally in favor of horizontal scaling): Horizontal scaling allows for more availability because if any one instance goes down, your capacity is temporarily reduced only a little bit. In contrast, with vertical scaling, any single instance going down hurts capacity a lot. On the other hand, horizontal scaling can reduce availability if the instances, being small, have less of a buffer to handle a single computationally intensive request, and temporarily go down on receiving such a request.
#* '''Cost stability''' (mixed, but generally in favor of horizontal scaling): For spot instances in particular, costs are more stable for smaller instances because of the larger number of people who use them. However, this is not uniformly true.
#* '''Shared memory''' (in favor of vertical scaling): If your application uses a lot of common in-memory data to process requests, then vertical scaling is better since it allows for the in-memory data to be shared. For instance, if you are providing a search engine and you store all the indexes in RAM, and the indexes use up 6 GB of data. If you use two m3.large instances, you are duplicating the 6 GB across both machines, and have only 1.5 GB (= 7.5 - 6) left for doing computation on each instance. On the other hand, if you use one m3.2xlarge, you have an effective 9 GB of memory left for doing computation. Even if you don't store all the data in-memory, but query it from a data store, shared memory can still help you by allowing you to cache resources. Note that the shared memory consideration is also relevant to deciding between instance classes, e.g., determining whether M or C makes more sense.

=== Understanding AWS regions and availability zones ===
# Understand the concept of an AWS region. AWS regions are names given to clusters of geographically nearby Amazon Web Services data centers. As of December 2016, there are twelve AWS regions (excluding AWS GovCloud):<ref name=rande>[http://docs.aws.amazon.com/general/latest/gr/rande.html Regions and endpoints, Amazon Web Services]</ref> four in the United States, five in Asia-Pacific, two in Europe, and one in South America. Additional AWS regions are expected to be added in Europe soon.<ref>[https://aws.amazon.com/blogs/aws/coming-in-2017-new-aws-region-in-france/ Coming in 2017 – New AWS Region in France], Jeff Barr, September 28, 2016</ref>
#* Round-trip times within an AWS region are approximately 2 milliseconds. 
#* Data transfer between different AWS services within a region, including to and from EC2 instances, is substantially cheaper than cross-region data transfer but not completely free.
#* Prices differ by AWS region, but are the same within a given AWS region.
# Understand the concept of an AWS availability zone (AZ).<ref>[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html Regions and Availability Zones]</ref>
#* The AZs are subdivisions within AWS regions. The number of AZs per region vary from 2 to 4.
#* The AZs are all isolated from each other, so that failures in one AZ (such as fires or electricity blackouts) should not adversely affect the operation of the other AZ.
#* The AZ for an EC2 instance is specified at the time of instance creation.
#* While the prices for on-demand and reserved instances are the same across different availability zones in a region, the spot instance markets are different for the different availability zones.
#* Reservations used to be tied to a particular availability zone. Starting September 2016, reservations can be given availability zone scope or region scope. If given region scope, the reservation is not tied to an availability zone.<ref>[https://aws.amazon.com/blogs/aws/ec2-reserved-instance-update-convertible-ris-and-regional-benefit/ EC2 Reserved Instance Update – Convertible RIs and Regional Benefit], Jeff Barr, Amazon Web Services Blog, September 29, 2016</ref> Instances reserved prior to that have availability zone scope but can be changed to region scope.

=== Understanding how Elastic Block Storage (EBS) affects costs ===

# Understand the two different kinds of disk storage Amazon offers for its EC2 instances.<ref>[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html Amazon Elastic Block Store (Amazon EBS)]</ref><ref name=aws-ebs>[https://aws.amazon.com/ebs/ Amazon EBS]</ref><ref>[http://searchaws.techtarget.com/definition/Amazon-EBS-Amazon-Elastic-Block-Store Amazon EBS (Amazon Elastic Block Store) definition]</ref>
#* Elastic Block Storage (EBS) is a high-throughput storage volume replicated across the availability zone. A given EBS can be attached to at most one EC2 instance at a time, but the instance to which it is attached can be changed. EBS can persist even when the instance is stopped and (if specified at launch) even after the instance is terminated.
#* Instance storage is local storage associated with a particular instance. It offers faster input/output but no redundancy and no persistence.
#* Depending on the Amazon Machine Image (AMI) used when launching an instance, the root volume of the instance may be either an EBS store or an instance store. The former types of instances are called EBS boot instances or EBS-backed instances.
#* New generation instances (C4, M4, R4, and C5) do not offer instance storage. They only support EBS.
# Understand the cost implications of using EBS-backed instances.<ref>[http://www.tomsitpro.com/articles/cost-of-the-cloud-book,2-694-2.html What You Need to Know About S3 and EBS]</ref>
#* The cost of an EBS instance depends on its size as specified when creating the volume.
#* EBS also charges for I/O. There are a few different kinds of EBS with different pricing models. For usual EBS, I/O charges occur whenever I/O occurs. For gp2, which is designed for high throughput, you are charged for provisioned throughput, rather than actual usage, but with a system of credit rollovers.
#* For EBS-backed instances, the EBS volumes persist even when the instance is stopped. For long-running instances, the EBS costs are quite small compared to the instance costs. However, for instances that are run for only a few hours a day and stopped the rest of the time, the EBS volumes can be a significant fraction of the overall costs. 
#* Depending on the settings used when launching the EBS, the EBS volume may or may not persist after the instance is terminated. If the volume persists, then that can cause significant cost leakage if the EBS volumes are not cleared out.
#* If you frequently provision new instances and do not automatically terminate the EBS upon termination of the instance, EBS can cause significant cost leakage.
# Understand how EBS snapshots work. An EBS snapshot stores a snapshot of the current content of the EBS to S3.<ref>[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html Amazon EBS Snapshots]</ref><ref>[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html Creating an Amazon EBS Snapshot]</ref>
#* Whereas an EBS is tied to an availability zone, the EBS snapshot is available throughout the region, so it can be retrieved in any availability zone within the region. It can also be transferred across regions.
#* Although EBS snapshots are stored in S3, the metadata to retrieve them is stored in the EBS system. They cannot be accessed directly as S3 objects. Thus, even though the underlying data is stored in a highly redundant fashion, the snapshots enjoy only 99.9% reliability (as opposed to 99.99%+ for S3).
#* EBS snapshots can be transferred across regions. The usual charges for cross-region data transfer apply.<ref>[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-copy-snapshot.html Copying an Amazon EBS Snapshot]</ref>
#* Storage for EBS snapshots is incremental, so that if an EBS is snapshotted multiple times, only the changed contents between snapshots are stored. The deletion process, however, is smart and reconstructs later snapshots before deleting earlier ones.<ref name=aws-ebs/> 

=== Understanding purchase options ===
# On-demand instances are the most expensive but the easiest to get started with.<ref>[https://aws.amazon.com/ec2/purchasing-options/ Purchasing Options]</ref>
#* On-demand instances can be spun up at any time, and are charged based on the instance type and the amount of time the instance is running.
#* On-demand instances may be stopped and restarted at any time. The instance is not charged for while it is stopped. The local storage (if any) of the instance is destroyed and any public IP associated with the instance is freed (unless it was an elastic IP). However, the Elastic Block Storage (EBS) associated with the instance is preserved, and AWS still charges for it.
#* On-demand instances may be terminated by the user at any time. After the on-demand instance is terminated, the corresponding Elastic Block Storage may or may not be deleted. This depends on the settings specified at launch.
#* AWS will not stop or terminate on-demand instances, though the instances may occasionally become unavailable due to hardware degradation or other data center issues.
#* On-demand instances are also eligible for termination protection that makes it a little harder for the user to accidentally terminate the instance.
# Spot instances are substantially cheaper than on-demand instances.
#* At the time of creation, the user creating the instance specifies the maximum spot price in addition to specifying the availability zone and instance type.
#* As long as the current spot price for that availability zone, and instance type is less than the maximum spot price, the instance can get created and will not get terminated. However, as soon as the current price exceeds the price of the spot instance, the instance gets terminated.
#* The price that is actually charged per unit time is the current spot price rather than the maximum spot price.
#* Spot instances cannot be stopped. They can only be terminated, either by the user or by AWS for price reasons.
#* The spot price for a spot instance cannot be changed after the instance has been created.
#* Spot instance pricing history by region, availability zone, and instance type is available on Amazon, and can be used to make smart bidding decisions.
#* There are limits on the number of spot instances that can be created by a given user for a given instance type and availability zone. These limits are generally much tighter than the limits associated with the overall number of instances, because of the havoc people can create by irresponsibly spinning up spot instances with high spot prices (and causing overall prices to spike). However, these limits can generally be increased upon request subject to capacity being available.<ref>[http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-limits.html Spot Instance Limits]</ref>
#* For some instance types and availability zones, particularly the I instance type, spinning up spot instances can take a lot of time due to the low overall spot capacity, despite a nominally low spot price.
# Reservations can be made for either 1 or 3 years, with three types of payment plans: no upfront, partial upfront, and all upfront.<ref>[https://aws.amazon.com/ec2/purchasing-options/reserved-instances/ Reserved Instances]</ref>
#* Some aspects of a reservation cannot be changed after the reservation is made. These include the time period for the reservation, the type of payment plan, the operating system, the tenancy type (dedicated versus default), and the region.
#* For standard reserved instances (standard RIs), the instance class and generation (such as R3, C3, M3, M4), cannot be changed.
#* For standard RIs, you ''can'' change the instance size within the same instance class and generation. The instance size can be changed while keeping the overall capacity the same. For instance, a reservation for three m3.xlarge instances can be changed to a reservation for one m3.2xlarge instance and one m3.xlarge instance.
#* If your reservations have availability zone scope, you need to switch the availability zone or change to region scope to use the reservation in a different availability zone.
#* Note that resizing instances, getting region scope, or changing availability zone, is not possible for reservations tied to operating systems that have license costs, such as Windows operating systems.
#* The reservation is not tied to any particular instance. In fact, the instances to which reservations apply are created the same way as on-demand instances. The way reservations work is that at every hour when the billing is calculated, the existing on-demand instances being used are checked against the reservations currently active. If any of the reservations apply, then the reduced prices based on the reservations apply to the instances. Otherwise, the full on-demand price applies.
#* For convertible reserved instances (convertible RIs) the instance class and generation can be changed. If the new configuration costs more than the old one, you pay the difference, if it costs less, AWS does not refund you the difference, but you can sell the excess capacity in the reserved instance marketplace.
=== Working on a robust instance-independent architecture ===
# Avoid the snowflake server mentality.<ref>[http://martinfowler.com/bliki/SnowflakeServer.html Snowflake Server]</ref> Invest extra time and effort into writing scripts (using tools such as Ansible or Chef) that allow you to, with a single command, deploy new instances for your applications. Make this script sufficiently flexible that you can deploy both on-demand and spot instances with the same script.
# If your application is handling variable loads from real-time web traffic, put the instances behind an elastic load balancer (ELB).
# Investigate autoscaling and use it if possible. Autoscaling allows you to scale up instance capacity in real time in response to load increases. It is a little extra work to set up.
# Maintain all critical long-lived data outside of individual EC2 instances (with the potential exception of special instances dedicated for data stores, which you periodically back up). To the extent possible, use S3 or databases for any long-lived data.
# Your scripts should be able to handle updates to your application smoothly. They could handle updates in any of the following ways:
#* The applications themselves can be updated on a live production instance without needing to take that instance offline. While this may be true of some types of updates, you should not rely on this as the only way the application can be updated.
#* New instances with the updated application code are deployed, and connected to the load balancer, and the old instances are then disconnected from the load balancer and terminated. For this kind of update, capacity is temporarily ''larger'' during the update. Note that the excess instance capacity will fall outside the reserved capacity, and therefore the new instances, if on-demand, will be charged at full on-demand rates during the transition.
#* Each of the existing instances is updated. If the current production load can be handled by fewer than the full set of instances, then the instances can be updated one by one: each instance is disconnected from the load balancer, updated, and then reconnected to the load balancer. For this kind of update, capacity is temporarily ''smaller'' during the update. If production loads vary by time of day, this kind of update can be done at a time when the production load is low.
# Set alarms for the load balancers to be able to detect too few healthy hosts, unusual traffic patterns, or a large number of errors.
# Spread instances across multiple availability zones within a region for more robustness against damage to a particular availability zone. Any availability zone in a given region can be activated for an ELB tied to that region.
# Use Route 53 health checks and failovers for cross-region redundancy in live serving.

=== Understanding hourly charging and the billing cycle ===
# Understand that instances are charged by the hour.
#* Every instance (whether on-demand or spot) is billed in discrete units of hours. The hourly cycle for an instance begins when it is first provisioned. An instance is billed for a full hour even if it is used for part of an hour. For instance, if an instance is used for 15 minutes, it is charged for an hour. If it is used for 65 minutes, it is charged for 2 hours.
#* The hours for each instance are calculated separately, so if two instances are each used for 5 minutes they will be charged for two hours.<ref>[http://serverfault.com/questions/245816/ec2-billing-for-fractional-hours EC2 billing for fractional hours]</ref>
#* If an instance is stopped and then restarted, a new hour is started every time the instance is restarted. So, if you stop and restart an instance four times in quick succession, you effectively get charged for four extra hours.<ref>[https://alestic.com/2010/10/ec2-stop-start/ EBS Boot Instance Stop+Start Begins a New Hour of Charges on EC2]</ref><ref>[http://developer.amazonwebservices.com/connect/message.jspa?messageID=191668 EC2 Forum question on stopping and restarting]</ref>
#* If an Amazon EC2 instance is terminated ''by Amazon'' (rather than by the user) it is not charged for the hour during which it is terminated. This is particularly relevant for spot instances that are subject to termination due to price.
 
=== Setting up tracking and monitoring ===
# In the Amazon EC2 console ("Reports" section), you can get reports on the Amazon EC2 costs (this does not include some data transfer costs) and the reserved instance utilization. You can break down the information by region, availability zone, instance class, instance type, and purchase option, and look at the usage on an hourly or daily basis. Data does not flow in immediately and can be delayed by 24-48 hours.
# Your AWS account has access to the billing data that provides the full breakdown of costs.  Set up a billing alert so that the data starts getting sent to Amazon CloudWatch. You can then set up more alerts using CloudWatch.<ref>[https://aws.amazon.com/blogs/aws/monitor-estimated-costs-using-amazon-cloudwatch-billing-metrics-and-alarms/ Monitor Estimated Charges Using Billing Alerts]</ref> CloudWatch data comes in as data points every few hours, but does not include a detailed breakdown.
# At any time, you can download detailed breakdown by hour and service type from your AWS account. This data is usually up to 6 hours late, though it can be even more delayed for some services.

=== Making and improve your purchase decisions ===
# Put all the factors together and start deciding. You need to figure out the mix of instances you'll use by instance class, instance type, region, availability zone, and purchase option.
# Ideally, aim to have all your instances either reserved or spot instances. There should be no unreserved on-demand capacity except very temporarily when spinning up new instances to replace existing ones.
#* However, since reservations entail a long-term commitment, it might make sense to use on-demand instances instead for mission-critical applications where the details of the instance types and capacity needed are still unclear.
#* In general, reservations give the most saving for more exotic instances (such as the D, I, or P instances) but are also the riskiest for these since these instances have very specific use cases where they are valuable.
# Keep monitoring costs over and above all the other things you are monitoring. Make sure that costs are part of the data you are looking at on a regular basis. Revisit your capacity decisions based on what you keep discovering.

== Related wikiHows ==

* [[Upload to Amazon S3]]
* [[Use Amazon Route 53]]
* [[Optimize Your Amazon S3 Costs]]
* [[Use Amazon EC2 Spot Instances]]

== Sources and citations ==

{{reflist}}

__PARTS__
